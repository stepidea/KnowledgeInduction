# 计算机组成原理（Computer Organization）

## 01 冯·诺伊曼体系结构

冯·诺依曼体系结构（Von Neumann architecture），也叫**存储程序**计算机。是“可编程”计算机和“存储”计算机。可阅读文档：[First Draft of a Report on the EDVAC](https://en.wikipedia.org/wiki/First_Draft_of_a_Report_on_the_EDVA)

计算机基本硬件组成：CPU、内存、主板（Motherboard）、电源、I/O 设备、显卡（Graphics Card）。

**任何一台计算机的任何一个部件都可以归到运算器、控制器、存储器、输入设备和输出设备中，而所有的现代计算机也都是基于这个基础架构来设计开发的。**

1. 一个包含算术逻辑单元（Arithmetic Logic Unit，ALU）和处理器寄存器（Processor Register）的**处理器单元**（Processing Unit），用来完成各种算术和逻辑运算。

2. 一个包含指令寄存器（Instruction Register）和程序计数器（Program Counter）的**控制器单元**（Control Unit/CU），用来控制程序的流程，通常就是不同条件下的分支和跳转。

3. 用来存储数据（Data）和指令（Instruction）的**内存**（memory），以及更大容量的外部存储，在过去，可能是磁带、磁鼓这样的设备，现在通常就是硬盘。

4. 各种**输入和输出设备**（I/O），以及对应的输入和输出机制。

------

由算术逻辑单元和控制器单元组成**中央处理器CPU**（Central Processing Unit），所有的**计算机程序**，也都可以抽象为从**输入设备**读取输入信息，通过**运算器**和**控制器**来执行存储在**存储器**里的程序，最终把结果输出到**输出设备**中。

## 02 计算机组成原理知识地图

计算机组成原理的知识点可分成了四大部分：**计算机的基本组成、计算机的指令和计算、处理器设计，以及存储器和 I/O 设备**。

![知识地图（from https://time.geekbang.org/column/article/92378）](https://raw.githubusercontent.com/stepidea/KnowledgeInduction/0df6f24ad11c5f000c7c0a8be1f8944b6e769914/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/image/computer_organization.png)

- 注：若图片无法显示一般是dns被污染（存放github图片素材的raw.githubusercontent.com站点），可修改hosts文件，增加节点：

  199.232.68.133 raw.githubusercontent.com
  199.232.68.133 githubusercontent.com

## 03 通过CPU主频谈计算机性能（时间的倒数）

**用于衡量计算机系统的指标**。第一个是**响应时间**（Response time）或者叫**执行时间**（Execution time），提升响应时间可以理解为让计算机“跑得更快”；第二个是**吞吐率**（Throughput）或者**带宽**（Bandwidth），提高吞吐率可以理解为让计算机“搬得更多”。

- *响应时间指执行一个程序，到底需要花多少时间。*

- *吞吐率是指在一定的时间范围内，到底能处理多少事情。*

所以我们一般把计算机性能，定义成响应时间的倒数，也就是：**性能 = 1/ 响应时间**；即响应时间越短，性能的数值就越大。（SPEC（Standard Performance Evaluation Corporation）标准性能评估公司 ）

计算机的计时单位：**CPU 时钟**

Linux下运行 time seq 1000000 | wc -l 命令。返回的第一个是 real time，也就是运行程序整个过程中流逝掉的时间（Wall Clock Time）；第二个是 user time，是 CPU 在运行你的程序，**在用户态运行指令的时间**；第三个是 sys time，是 CPU 在运行你的程序，**在操作系统内核里运行指令的时间**。而<u>程序实际花费的 CPU 执行时间（CPU Time），就是 user time 加上 sys time。</u>

同一台计算机上，响应时间会受到CPU（可能满载运行也可能降频运行）、主板、内存这些其他相关硬件的影响；所以**程序的 CPU 执行时间变成 CPU 时钟周期数（CPU Cycles）和 时钟周期时间（Clock Cycle）的乘积**。

​	**程序的 CPU 执行时间 =CPU 时钟周期数×时钟周期时间**

CPU 时钟周期数，我们可以再做一个分解，把它变成“指令数（不同的指令需要的 Cycles 是不同的）×每条指令的平均时钟周期数（Cycles Per Instruction，简称 CPI）”。

​	**程序的 CPU 执行时间 = 指令数×CPI×Clock Cycle Time**

1. *时钟周期时间，就是计算机主频，这个取决于计算机硬件。*
2. *每条指令的平均时钟周期数 CPI，就是一条指令到底需要多少 CPU Cycle。*
3. *指令数，代表执行我们的程序到底需要多少条指令、用哪些指令。*

## 04 功耗影响计算机性能

**功耗：CPU 的“人体极限”**。CPU，一般都被叫作**超大规模集成电路**（Very-Large-Scale Integration，VLSI）。这些电路，实际上都是一个个**晶体管**组合而成的。CPU 在计算，其实就是让晶体管里面的“开关”不断地去“打开”和“关闭”，来组合完成各种运算和功能。想要计算得快，一方面，我们要在 CPU 里，同样的面积里面，多放一些晶体管，也就是**增加密度**；另一方面，我们要让晶体管“打开”和“关闭”得更快一点，也就是**提升主频**。而这两者，都会增加功耗，带来**耗电和散热**的问题。

因此，在 CPU 里面，能够放下的晶体管数量和晶体管的“开关”频率也都是有限的。一个 CPU 的功率，可以用这样一个公式来表示：

​	**功耗 ~= 1/2 ×负载电容×电压的平方×开关频率×晶体管数量**

为了要提升性能，我们需要不断地增加晶体管数量。同样的面积下，我们想要多放一点晶体管，就要把晶体管造得小一点。这个就是平时我们所说的提升“制程”。从 28nm 到 7nm，相当于晶体管本身变成了原来的 1/4 大小。（我们在工厂里，同样的活儿，我们要找瘦小一点的工人，这样一个工厂里面就可以多一些人。我们还要提升主频，让开关的频率变快，也就是要找手脚更快的工人。）

**并行优化，理解阿姆达尔定律**。从奔腾 4 开始，Intel 意识到通过提升主频比较“难”去实现性能提升，边开始推出 Core Duo 这样的多核 CPU，通过提升“吞吐率”而不是“响应时间”，来达到目的。比如我们现在用的 2 核、4 核，乃至 8 核的 CPU。（我们做机器学习程序的时候，需要计算向量的点积，比如向量 W=[W0,W1,W2,…,W15] 和向量 X=[X0,X1,X2,…,X15]，W⋅X=W0∗X0+W1∗X1+ W2∗X2+…+W15∗X15。这些式子由 16 个乘法和 1 个连加组成。如果你自己一个人用笔来算的话，需要一步一步算 16 次乘法和 15 次加法。如果这个时候我们把这个任务分配给 4 个人，同时去算 W0～W3, W4～W7, W8～W11, W12～W15 这样四个部分的结果，再由一个人进行汇总，需要的时间就会缩短。）

通过并行提高性能。如果想要使用这种思想，需要满足这样几个条件。

1. 需要进行的计算，本身可以分解成几个可以并行的任务。好比上面的乘法和加法计算，几个人可以同时进行，不会影响最后的结果。
2. 需要能够分解好问题，并确保几个人的结果能够汇总到一起。
3. 在“汇总”这个阶段，是没有办法并行进行的，还是得顺序执行，一步一步来。

经验定律:**阿姆达尔定律**（Amdahl’s Law）。对于一个程序进行优化之后，处理器并行运算之后效率提升的情况。具体可以用这样一个公式来表示：

​	优化后的执行时间 = 受优化影响的执行时间 / 加速倍数 + 不受影响的执行时间

（向量点积例子里，4 个人同时计算向量的一小段点积，就是通过并行提高了这部分的计算性能。但是，这 4 个人的计算结果，最终还是要在一个人那里进行汇总相加。这部分汇总相加的时间，是不能通过并行来优化的，也就是上面的公式里面不受影响的执行时间这一部分。）

在“**摩尔定律**”和“**并行计算**”之外，在整个计算机组成层面，原则性的性能提升方法：

1. **加速大概率事件**。最典型的就是，过去几年流行的深度学习，整个计算过程中，99% 都是向量和矩阵计算，于是，工程师们通过用 GPU 替代 CPU，大幅度提升了深度学习的模型训练过程。本来一个 CPU 需要跑几小时甚至几天的程序，GPU 只需要几分钟就好了。Google 更是不满足于 GPU 的性能，进一步地推出了 TPU。
2. **通过流水线提高性能**。现代的工厂里的生产线叫“流水线”。我们可以把装配 iPhone 这样的任务拆分成一个个细分的任务，让每个人都只需要处理一道工序，最大化整个工厂的生产效率。类似的，我们的 CPU 其实就是一个“运算工厂”。我们把 CPU 指令执行的过程进行拆分，细化运行，也是现代 CPU 在主频没有办法提升那么多的情况下，性能仍然可以得到提升的重要原因之一。
3. **通过预测提高性能**。通过预先猜测下一步该干什么，而不是等上一步运行的结果，提前进行运算，也是让程序跑得更快一点的办法。典型的例子就是在一个循环访问数组的时候，凭经验，你也会猜到下一步我们会访问数组的下一项。后面要讲的“分支和冒险”、“局部性原理”这些 CPU 和存储系统设计方法，其实都是在利用我们对于未来的“预测”，提前进行相应的操作，来提升我们的程序性能。

## **10 动态链接**

程序连接

